{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad362e02",
   "metadata": {},
   "source": [
    "# GMO Forecasting\n",
    "\n",
    "*Case: Grantham, Mayo, and Van Otterloo, 2012: Estimating the Equity Risk Premium\n",
    "[9-211-051].*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\E}{\\mathbb{E}}\n",
    "\\newcommand{\\cond}{\\, |\\, }\n",
    "\\newcommand{\\var}{\\text{var}}\n",
    "\\newcommand{\\cov}{\\text{cov}}\n",
    "\\newcommand{\\corr}{\\text{corr}}\n",
    "\\newcommand{\\std}{\\text{std}}\n",
    "\\newcommand{\\covmat}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\cdf}{\\Phi}\n",
    "\\newcommand{\\Normal}{\\mathcal{N}}\n",
    "\\newcommand{\\lp}{\\mathbb{L}}\n",
    "\\newcommand{\\dlim}{\\overset{D}{\\to \\;}}\n",
    "\\newcommand{\\plim}{\\overset{P}{\\to \\;}}\n",
    "\\newcommand{\\iid}{i.i.d.}\n",
    "\\newcommand{\\free}{f}\n",
    "\\newcommand{\\ex}[1]{\\tilde{#1}}\n",
    "\\newcommand{\\R}[1][]{R^{#1}}\n",
    "\\newcommand{\\Rf}{\\R[\\free]}\n",
    "\\newcommand{\\Rx}[1][]{\\ex{R}^{#1}}\n",
    "\\renewcommand{\\r}[1][]{r^{\\scriptscriptstyle {#1}}}\n",
    "\\newcommand{\\rf}{\\r[\\free]}\n",
    "\\newcommand{\\rx}[1][]{\\ex{r}^{\\scriptscriptstyle {#1}}}\n",
    "\\newcommand{\\rlog}[1][]{{\\texttt{r}^{#1}}}\n",
    "\\newcommand{\\rflog}{\\rlog[\\free]}\n",
    "\\newcommand{\\rvec}[1][]{\\boldsymbol{\\r[#1]}}\n",
    "\\newcommand{\\rxvec}[1][]{\\boldsymbol{\\rx[#1]}}\n",
    "\\newcommand{\\pay}[1][]{\\Gamma^{\\scriptscriptstyle {#1}}}\n",
    "\\renewcommand{\\P}{\\mathcal{P}}\n",
    "\\newcommand{\\ind}[1]{_{[#1]}}\n",
    "\\newcommand{\\notind}[1]{\\ind{-#1}}\n",
    "\\newcommand{\\coord}{\\boldsymbol{\\iota}}\n",
    "\\newcommand{\\obs}{n}\n",
    "\\newcommand{\\Nobs}{N}\n",
    "\\newcommand{\\lag}{h}\n",
    "\\newcommand{\\Nlag}{H}\n",
    "\\newcommand{\\indx}{i}\n",
    "\\newcommand{\\indxalt}{j}\n",
    "\\newcommand{\\I}{\\mathcal{I}}\n",
    "\\newcommand{\\one}{\\textbf{1}}\n",
    "\\newcommand{\\zeros}{\\textbf{0}}\n",
    "\\newcommand{\\x}{\\textbf{x}}\n",
    "\\newcommand{\\z}{\\textbf{z}}\n",
    "\\newcommand{\\y}{\\textbf{y}}\n",
    "\\newcommand{\\w}{\\textbf{w}}\n",
    "\\newcommand{\\X}{\\textbf{X}}\n",
    "\\newcommand{\\Z}{\\textbf{Z}}\n",
    "\\newcommand{\\Y}{\\textbf{Y}}\n",
    "\\newcommand{\\W}{\\textbf{W}}\n",
    "\\newcommand{\\alphavec}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\betavec}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\epsilonvec}{\\boldsymbol{\\epsilon}}\n",
    "\\newcommand{\\sigmavec}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\mux}{\\ex{\\mu}}\n",
    "\\newcommand{\\muvec}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\muxvec}{\\boldsymbol{\\ex{\\mu}}}\n",
    "\\newcommand{\\muP}{\\mu^p}\n",
    "\\newcommand{\\Sigmamat}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\wt}{\\boldsymbol{\\omega}}\n",
    "\\newcommand{\\wtx}{\\boldsymbol{w}}\n",
    "\\newcommand{\\wtxstar}{\\wtx^*}\n",
    "\\newcommand{\\wtTan}{\\wt^{\\tan}}\n",
    "\\newcommand{\\wtxTan}{\\wtx^{\\tan}}\n",
    "\\newcommand{\\wtGMV}{\\wt^{\\gmv}}\n",
    "\\newcommand{\\mv}{\\scriptscriptstyle {\\subset}}\n",
    "\\newcommand{\\MV}{$\\ex{\\text{MV}}\\ $}\n",
    "\\newcommand{\\MVscale}{\\delta}\n",
    "\\newcommand{\\ifac}{k}\n",
    "\\newcommand{\\Nfacs}{k}\n",
    "\\newcommand{\\fbeta}[1][]{\\beta^{\\scriptscriptstyle {#1}}}\n",
    "\\newcommand{\\fbetavec}[1][]{\\betavec^{\\scriptscriptstyle {#1}}}\n",
    "\\newcommand{\\radon}{q}\n",
    "\\newcommand{\\mkt}{m}\n",
    "\\newcommand{\\act}{a}\n",
    "\\renewcommand{\\tan}{\\texttt{t}}\n",
    "\\newcommand{\\gmv}{\\texttt{v}}\n",
    "\\newcommand{\\size}{s}\n",
    "\\newcommand{\\val}{v}\n",
    "\\newcommand{\\up}{u}\n",
    "\\newcommand{\\mom}{\\text{mom}}\n",
    "\\newcommand{\\orthog}{\\alpha}\n",
    "\\newcommand{\\fac}{z}\n",
    "\\newcommand{\\facs}{\\boldsymbol{z}}\n",
    "\\newcommand{\\facmac}{f}\n",
    "\\newcommand{\\facsmac}{\\boldsymbol{f}}\n",
    "\\newcommand{\\prem}{\\lambda}\n",
    "\\newcommand{\\premvec}{\\boldsymbol{\\prem}}\n",
    "\\newcommand{\\pos}{i}\n",
    "\\newcommand{\\hedge}{j}\n",
    "\\newcommand{\\etavec}{\\boldsymbol{\\eta}}\n",
    "\\newcommand{\\Q}{\\textbf{Q}}\n",
    "\\newcommand{\\eig}{\\psi}\n",
    "\\newcommand{\\Eig}{\\Psi}\n",
    "\\newcommand{\\eigv}{\\textbf{q}}\n",
    "\\newcommand{\\Eigv}{Q}\n",
    "\\newcommand{\\PCwt}{\\textbf{q}}\n",
    "\\newcommand{\\PCfac}{x}\n",
    "\\newcommand{\\VaR}{\\text{VaR}}\n",
    "\\newcommand{\\ES}{\\text{ES}}\n",
    "\\newcommand{\\Rrate}{\\,\\r}\n",
    "\\newcommand{\\Rratevec}{\\,\\rvec}\n",
    "\\newcommand{\\RVaR}{\\, \\r[\\text{VaR}]}\n",
    "\\newcommand{\\RES}{\\,\\r[\\text{ES}]}\n",
    "\\newcommand{\\rVaR}{\\, \\r[\\text{VaR}]}\n",
    "\\newcommand{\\rES}{\\, \\r[\\text{ES}]}\n",
    "\\newcommand{\\thresh}{\\pi}\n",
    "\\newcommand{\\quantile}{\\texttt{z}_{\\thresh}}\n",
    "\\newcommand{\\gain}{\\Delta V}\n",
    "\\newcommand{\\loss}{L}\n",
    "\\newcommand{\\lossvec}{\\textbf{L}}\n",
    "\\newcommand{\\cdfnorm}{\\Phi}\n",
    "\\newcommand{\\cdflosst}{F^\\ell_\\tau}\n",
    "\\newcommand{\\cdfgaint}{F^g_\\tau}\n",
    "\\newcommand{\\cdfretst}{F^{\\r}_\\tau}\n",
    "\\newcommand{\\invcdflosst}{F_\\tau^{\\ell(-1)}}\n",
    "\\newcommand{\\invcdfgaint}{F_\\tau^{g[-1]}}\n",
    "\\newcommand{\\invcdfretst}{F^{\\r(-1)}_\\tau}\n",
    "\\newcommand{\\mawt}{\\theta}\n",
    "\\newcommand{\\DP}{\\text{DP}}\n",
    "\\newcommand{\\n}{{(n)}}\n",
    "\\newcommand{\\0}{(0)}\n",
    "\\newcommand{\\1}{{(1)}}\n",
    "\\newcommand{\\2}{{(2)}}\n",
    "\\newcommand{\\3}{{(3)}}\n",
    "\\newcommand{\\4}{{(4)}}\n",
    "\\newcommand{\\5}{{(5)}}\n",
    "\\newcommand{\\bonds}{B}\n",
    "\\newcommand{\\fx}{S}\n",
    "\\newcommand{\\fxlog}{\\texttt{s}}\n",
    "\\newcommand{\\meuro}{\\text{\\euro}}\n",
    "\\newcommand{\\usd}{\\$}\n",
    "\\newcommand{\\for}{F}\n",
    "\\newcommand{\\forlog}{\\texttt{f}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {},
   "source": [
    "## 1 READING: GMO\n\nThis section is not graded, and you do not need to submit your answers. But you are expected to consider these issues and be ready to discuss them.\n\n1. **GMO’s approach.**\n   - Why does GMO believe they can more easily predict **long‑run** than **short‑run** asset‑class performance?\n\n<font color='red'>\n\nGMO believes that \"in the short run, the market is a voting machine, but in the long run, the market is a weighing machine\". So specifically, they thing that in the long run, asset returns should converge to their fundamental values (\"steady state\"), but that in the short run there may be significant deviation from said values due to noise. They also believe that there is a long-run equity risk premia, ie. that equities should outperform bonds in the long run because of the \"inconvenient return path\" (they tend to lose value when you least want them to).\n\n</font>\n\n   - What predicting variables does the case mention are used by GMO? Does this fit with the goal of long‑run forecasts?\n\n<font color='red'>\n\nThe case mentions dividend yield, P/E (Price/Earnings) multiple expansion and contraction, sales growth, and profit margin as predicting variables used by GMO. GMO believes that profit margin and P/E multiple should be stable in the long-run, and that long-run returns are principally driven by sales growth and required dividend yield. They also used the \"Gordon Growth Model\" as a basis for their forecasts.\n\nThis does fit the goal of long-run forecasts; using things other than purely price (so more fundamental drivers) helps avoid market noise that may affect short-term prices but not long-term values.\n\n</font>\n\n   - How has this approach led to **contrarian** positions?\n\n<font color='red'>\n\nBecause they think that P/E multiples and dividend yield should be stable and reverting to some fundamental value, it means that when equity markets have elevated multiples or are frothy (lots of buyers), they will take an underweight position. \n\nThey were also typically more conservative, but took large risks when the \"fat pitch\" presented itself. They also heavily believed in a value-oriented approach to asset allocation, and had a lot of dry powder to deploy when the opportunity came (cash).\n\n</font>\n\n   - How does this approach raise **business risk** and **managerial career risk**?\n\n<font color='red'>\n\nThe first risk, business risk, is a result of a fund needing to secure capital long enough to see its thesis become realized. As a contrarian with a long term perspective, GMO is likely to suffer from severe underperformance while it waits for its thesis to play out. Many investors are not patient enough and may withrdraw their money, leaving GMO with no ability to function at all. In particular, GMO was bearish from 1997 and 2000, and lost 60% of their assets due to withdrawals.\n\nSecondly, there is career risk. The risk here is that many investment professionals are driven by their concern for their position, which is largely determined by short(er) term performance. One may be reluctant to stand out if the risk of them, and them alone, being wrong leads to them being fired.\n\n</font>\n\n2. **The market environment.**\n   - We often estimate the market risk premium by looking at a large sample of historic data. What reasons does the case give to be skeptical that the market risk premium will be as high **in the future** as it has been **over the past 50 years**?\n\n<font color='red'>\n\nGMO had a bearish outlook on stocks, with stocks only outperforming bonds by 1.6% over the next 7 years (as of 2011, Exhibit 10). The case mentions that even after 2008, PE ratios were at 19.9, well above the long-run average of 16. They were also \"skeptical that US firms could sustain the record profit margins they had delivered since 2009, GMO was also pessimistic about future earnings growth. However, over the longer run, GMO was confident that stocks would continue to earn a healthy risk premium. Inker thought that 'reports of the death of equities had been greatly exagerated.'\"\n\n</font>\n\n   - In 2007, GMO forecasts **real excess equity returns** will be negative. What are the biggest drivers of their **pessimistic conditional** forecast relative to the **unconditional** forecast? (See Exhibit 9.)\n\n<font color='red'>\n\nFrom exhibit 9, they expected P/E to contract by 2.8% over the next 7 years, they also expected profit margins to contract by 3.9%. These were the two biggest drivers of their pessimistic forecast.\n\nFor the unconditional (steady state) forecast, they expected no change in P/E or profit margins relative to their historic steady states (16 and 6%, respectively).\n\n</font>\n\n   - In the 2011 forecast, what components has GMO revised most relative to 2007? Now how does their conditional forecast compare to the unconditional? (See Exhibit 10.)\n\n<font color='red'>\n\nIn 2011, they expected PE ratios to not change (0.0%), a big revision from the -2.8% in 2007. In 2011 the PE ratio was 15, and they actually downgraded their unconditional forecast down 15 (from 16). They also slightly revised their profit margin contraction to 3.7%, up from 3.9% in 2007. Finally, they revised their expected sales growth per share up to 2.9%, up from 2.4% in 2007. This meant that their overall forecast was now 1.6% excess return over bonds, up signfificantly from -3.9% in 2007.\n\n</font>\n\n3. **Consider the asset‑class forecasts in Exhibit 1.**\n   - Which asset class did GMO estimate to have a **negative 10‑year return** over 2002–2011?\n<font color='red'>\nThey only expected the S&P 500 to have a negative return of ~-1% per year over the next 10 years.\n</font>\n\n   - Which asset classes substantially **outperformed** GMO’s estimate over that time period?\n<font color='red'>\nForeign government bonds, and emerging market equities. For foreign government bonds, they expected a return of ~3% but they returned 6%, and for emerging market equities they expected ~9.5% but they returned ~11.5%. There's also an argument to be made for US large cap equities, they expected -1% but they actually returned about 0.5%.\n</font>\n\n   - Which asset classes substantially **underperformed** GMO’s estimate over that time period?\n<font color='red'>\nUS Treasury bills, forecast 2% but returns -0.5%. Also, US REITs, they forecast a little over 8% but they returned ~6.5%.\n</font>\n\n4. **Fund performance.**\n   - In which asset class was **GMWAX** most heavily allocated throughout the majority of 1997–2011?\n\n<font color='red'>\nUS Fixed Income by far, followed by international equities and then US equities.\n</font>\n\n   - Comment on the performance of GMWAX versus its benchmark. (No calculation needed; simply comment on the comparison in the exhibits.)\n\n<font color='red'>\nGMWAX was very successful relative to its benchmark, with double the returns and only 70% of the volatility, so the Sharpe ratio was more than double. Worth noting though that in my opinion this isn't really good, the Sharpe ratio was 0.46, which is extremely mediocre in absolute terms.\n</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ecae5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and such\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "plt.style.use(\"bmh\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "\n",
    "\n",
    "def calc_return_metrics(data, as_df=False, adj=12):\n",
    "    \"\"\"\n",
    "    Calculate return metrics for a DataFrame of assets.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame of asset returns.\n",
    "        as_df (bool, optional): Return a DF or a dict. Defaults to False (return a dict).\n",
    "        adj (int, optional): Annualization. Defaults to 12.\n",
    "\n",
    "    Returns:\n",
    "        Union[dict, DataFrame]: Dict or DataFrame of return metrics.\n",
    "    \"\"\"\n",
    "    summary = dict()\n",
    "    summary[\"Annualized Return\"] = data.mean() * adj\n",
    "    summary[\"Annualized Volatility\"] = data.std() * np.sqrt(adj)\n",
    "    summary[\"Annualized Sharpe Ratio\"] = (\n",
    "        summary[\"Annualized Return\"] / summary[\"Annualized Volatility\"]\n",
    "    )\n",
    "    summary[\"Annualized Sortino Ratio\"] = summary[\"Annualized Return\"] / (\n",
    "        data[data < 0].std() * np.sqrt(adj)\n",
    "    )\n",
    "    return pd.DataFrame(summary, index=data.columns) if as_df else summary\n",
    "\n",
    "\n",
    "def calc_risk_metrics(data, as_df=False, var=0.05):\n",
    "    \"\"\"\n",
    "    Calculate risk metrics for a DataFrame of assets.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame of asset returns.\n",
    "        as_df (bool, optional): Return a DF or a dict. Defaults to False.\n",
    "        adj (int, optional): Annualizatin. Defaults to 12.\n",
    "        var (float, optional): VaR level. Defaults to 0.05.\n",
    "\n",
    "    Returns:\n",
    "        Union[dict, DataFrame]: Dict or DataFrame of risk metrics.\n",
    "    \"\"\"\n",
    "    summary = dict()\n",
    "    summary[\"Skewness\"] = data.skew()\n",
    "    summary[\"Excess Kurtosis\"] = data.kurtosis()\n",
    "    summary[f\"VaR ({var})\"] = data.quantile(var, axis=0)\n",
    "    summary[f\"CVaR ({var})\"] = data[data <= data.quantile(var, axis=0)].mean()\n",
    "    summary[\"Min\"] = data.min()\n",
    "    summary[\"Max\"] = data.max()\n",
    "\n",
    "    wealth_index = 1000 * (1 + data).cumprod()\n",
    "    previous_peaks = wealth_index.cummax()\n",
    "    drawdowns = (wealth_index - previous_peaks) / previous_peaks\n",
    "\n",
    "    summary[\"Max Drawdown\"] = drawdowns.min()\n",
    "\n",
    "    summary[\"Bottom\"] = drawdowns.idxmin()\n",
    "    summary[\"Peak\"] = previous_peaks.idxmax()\n",
    "\n",
    "    recovery_date = []\n",
    "    for col in wealth_index.columns:\n",
    "        prev_max = previous_peaks[col][: drawdowns[col].idxmin()].max()\n",
    "        recovery_wealth = pd.DataFrame([wealth_index[col][drawdowns[col].idxmin() :]]).T\n",
    "        recovery_date.append(\n",
    "            recovery_wealth[recovery_wealth[col] >= prev_max].index.min()\n",
    "        )\n",
    "    summary[\"Recovery\"] = [\"-\" if pd.isnull(i) else i for i in recovery_date]\n",
    "\n",
    "    summary[\"Duration (days)\"] = [\n",
    "        (i - j).days if i != \"-\" else \"-\"\n",
    "        for i, j in zip(summary[\"Recovery\"], summary[\"Bottom\"])\n",
    "    ]\n",
    "\n",
    "    return pd.DataFrame(summary, index=data.columns) if as_df else summary\n",
    "\n",
    "\n",
    "def calc_performance_metrics(data, adj=12, var=0.05):\n",
    "    \"\"\"\n",
    "    Aggregating function for calculating performance metrics. Returns both\n",
    "    risk and performance metrics.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame of asset returns.\n",
    "        adj (int, optional): Annualization. Defaults to 12.\n",
    "        var (float, optional): VaR level. Defaults to 0.05.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame of performance metrics.\n",
    "    \"\"\"\n",
    "    summary = {\n",
    "        **calc_return_metrics(data=data, adj=adj),\n",
    "        **calc_risk_metrics(data=data, var=var),\n",
    "    }\n",
    "    summary[\"Calmar Ratio\"] = summary[\"Annualized Return\"] / abs(\n",
    "        summary[\"Max Drawdown\"]\n",
    "    )\n",
    "    return pd.DataFrame(summary, index=data.columns)\n",
    "\n",
    "\n",
    "rets = pd.read_excel(\n",
    "    \"gmo_data.xlsx\", sheet_name=\"total returns\", index_col=\"date\", parse_dates=True\n",
    ")\n",
    "rfr = (\n",
    "    pd.read_excel(\n",
    "        \"gmo_data.xlsx\", sheet_name=\"risk-free rate\", index_col=\"date\", parse_dates=True\n",
    "    )\n",
    "    / 12\n",
    ")\n",
    "\n",
    "# Calculate excess returns\n",
    "retsx = rets.subtract(rfr[\"TBill 3M\"], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "source": [
    "## 2 Analyzing GMO\n\n_This section utilizes data in the file `gmo_data.xlsx`._ Convert total returns to **excess returns** using the risk‑free rate.\n\n1. **Performance (GMWAX).** Compute **mean**, **volatility**, and **Sharpe ratio** for **GMWAX** over three samples:\n   - inception → 2011\n   - 2012 → present\n   - inception → present  \n   Has the mean, vol, and Sharpe changed much since the case?\n\n2. **Tail risk (GMWAX).** For all three samples, analyze extreme scenarios:\n   - minimum return\n   - 5th percentile (VaR‑5th)\n   - maximum drawdown (compute on **total** returns, not excess returns)  \n   (a) Does GMWAX have high or low tail‑risk as seen by these stats?  \n   (b) Does that vary much across the two subsamples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac2c998b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GMWAX (Start-2011)</th>\n",
       "      <th>GMGEX (Start-2011)</th>\n",
       "      <th>GMWAX (2012-Present)</th>\n",
       "      <th>GMGEX (2012-Present)</th>\n",
       "      <th>GMWAX (Start-Present)</th>\n",
       "      <th>GMGEX (Start-Present)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annualized Return</th>\n",
       "      <td>0.046422</td>\n",
       "      <td>-0.003823</td>\n",
       "      <td>0.043423</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.045043</td>\n",
       "      <td>-0.001463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annualized Volatility</th>\n",
       "      <td>0.110499</td>\n",
       "      <td>0.147253</td>\n",
       "      <td>0.094949</td>\n",
       "      <td>0.235554</td>\n",
       "      <td>0.10349</td>\n",
       "      <td>0.192622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annualized Sharpe Ratio</th>\n",
       "      <td>0.42011</td>\n",
       "      <td>-0.025963</td>\n",
       "      <td>0.457326</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>0.43524</td>\n",
       "      <td>-0.007595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annualized Sortino Ratio</th>\n",
       "      <td>0.52979</td>\n",
       "      <td>-0.035968</td>\n",
       "      <td>0.658023</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>0.573957</td>\n",
       "      <td>-0.007213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skewness</th>\n",
       "      <td>-0.891709</td>\n",
       "      <td>-0.509564</td>\n",
       "      <td>-0.507077</td>\n",
       "      <td>-6.028372</td>\n",
       "      <td>-0.758222</td>\n",
       "      <td>-5.131245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Excess Kurtosis</th>\n",
       "      <td>3.058298</td>\n",
       "      <td>0.672829</td>\n",
       "      <td>1.945528</td>\n",
       "      <td>57.473216</td>\n",
       "      <td>2.771186</td>\n",
       "      <td>58.272763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VaR (0.05)</th>\n",
       "      <td>-0.044003</td>\n",
       "      <td>-0.082292</td>\n",
       "      <td>-0.040854</td>\n",
       "      <td>-0.068027</td>\n",
       "      <td>-0.041368</td>\n",
       "      <td>-0.076213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVaR (0.05)</th>\n",
       "      <td>-0.074072</td>\n",
       "      <td>-0.09856</td>\n",
       "      <td>-0.058858</td>\n",
       "      <td>-0.162657</td>\n",
       "      <td>-0.068849</td>\n",
       "      <td>-0.130719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min</th>\n",
       "      <td>-0.14915</td>\n",
       "      <td>-0.151592</td>\n",
       "      <td>-0.115018</td>\n",
       "      <td>-0.658863</td>\n",
       "      <td>-0.14915</td>\n",
       "      <td>-0.658863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max</th>\n",
       "      <td>0.081877</td>\n",
       "      <td>0.096042</td>\n",
       "      <td>0.074458</td>\n",
       "      <td>0.124668</td>\n",
       "      <td>0.081877</td>\n",
       "      <td>0.124668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Drawdown</th>\n",
       "      <td>-0.293614</td>\n",
       "      <td>-0.55563</td>\n",
       "      <td>-0.216795</td>\n",
       "      <td>-0.737364</td>\n",
       "      <td>-0.293614</td>\n",
       "      <td>-0.761812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bottom</th>\n",
       "      <td>2009-02-27 00:00:00</td>\n",
       "      <td>2009-02-27 00:00:00</td>\n",
       "      <td>2022-09-30 00:00:00</td>\n",
       "      <td>2016-11-30 00:00:00</td>\n",
       "      <td>2009-02-27 00:00:00</td>\n",
       "      <td>2016-11-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peak</th>\n",
       "      <td>2011-04-29 00:00:00</td>\n",
       "      <td>2007-10-31 00:00:00</td>\n",
       "      <td>2024-09-30 00:00:00</td>\n",
       "      <td>2014-06-30 00:00:00</td>\n",
       "      <td>2024-09-30 00:00:00</td>\n",
       "      <td>2007-10-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recovery</th>\n",
       "      <td>2010-10-29 00:00:00</td>\n",
       "      <td>-</td>\n",
       "      <td>2024-02-29 00:00:00</td>\n",
       "      <td>-</td>\n",
       "      <td>2010-10-29 00:00:00</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Duration (days)</th>\n",
       "      <td>609</td>\n",
       "      <td>-</td>\n",
       "      <td>517</td>\n",
       "      <td>-</td>\n",
       "      <td>609</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar Ratio</th>\n",
       "      <td>0.151448</td>\n",
       "      <td>-0.006779</td>\n",
       "      <td>0.192465</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.14695</td>\n",
       "      <td>-0.001905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           GMWAX (Start-2011)   GMGEX (Start-2011)  \\\n",
       "Annualized Return                    0.046422            -0.003823   \n",
       "Annualized Volatility                0.110499             0.147253   \n",
       "Annualized Sharpe Ratio               0.42011            -0.025963   \n",
       "Annualized Sortino Ratio              0.52979            -0.035968   \n",
       "Skewness                            -0.891709            -0.509564   \n",
       "Excess Kurtosis                      3.058298             0.672829   \n",
       "VaR (0.05)                          -0.044003            -0.082292   \n",
       "CVaR (0.05)                         -0.074072             -0.09856   \n",
       "Min                                  -0.14915            -0.151592   \n",
       "Max                                  0.081877             0.096042   \n",
       "Max Drawdown                        -0.293614             -0.55563   \n",
       "Bottom                    2009-02-27 00:00:00  2009-02-27 00:00:00   \n",
       "Peak                      2011-04-29 00:00:00  2007-10-31 00:00:00   \n",
       "Recovery                  2010-10-29 00:00:00                    -   \n",
       "Duration (days)                           609                    -   \n",
       "Calmar Ratio                         0.151448            -0.006779   \n",
       "\n",
       "                         GMWAX (2012-Present) GMGEX (2012-Present)  \\\n",
       "Annualized Return                    0.043423             0.001311   \n",
       "Annualized Volatility                0.094949             0.235554   \n",
       "Annualized Sharpe Ratio              0.457326             0.005566   \n",
       "Annualized Sortino Ratio             0.658023             0.004641   \n",
       "Skewness                            -0.507077            -6.028372   \n",
       "Excess Kurtosis                      1.945528            57.473216   \n",
       "VaR (0.05)                          -0.040854            -0.068027   \n",
       "CVaR (0.05)                         -0.058858            -0.162657   \n",
       "Min                                 -0.115018            -0.658863   \n",
       "Max                                  0.074458             0.124668   \n",
       "Max Drawdown                        -0.216795            -0.737364   \n",
       "Bottom                    2022-09-30 00:00:00  2016-11-30 00:00:00   \n",
       "Peak                      2024-09-30 00:00:00  2014-06-30 00:00:00   \n",
       "Recovery                  2024-02-29 00:00:00                    -   \n",
       "Duration (days)                           517                    -   \n",
       "Calmar Ratio                         0.192465             0.001776   \n",
       "\n",
       "                         GMWAX (Start-Present) GMGEX (Start-Present)  \n",
       "Annualized Return                     0.045043             -0.001463  \n",
       "Annualized Volatility                  0.10349              0.192622  \n",
       "Annualized Sharpe Ratio                0.43524             -0.007595  \n",
       "Annualized Sortino Ratio              0.573957             -0.007213  \n",
       "Skewness                             -0.758222             -5.131245  \n",
       "Excess Kurtosis                       2.771186             58.272763  \n",
       "VaR (0.05)                           -0.041368             -0.076213  \n",
       "CVaR (0.05)                          -0.068849             -0.130719  \n",
       "Min                                   -0.14915             -0.658863  \n",
       "Max                                   0.081877              0.124668  \n",
       "Max Drawdown                         -0.293614             -0.761812  \n",
       "Bottom                     2009-02-27 00:00:00   2016-11-30 00:00:00  \n",
       "Peak                       2024-09-30 00:00:00   2007-10-31 00:00:00  \n",
       "Recovery                   2010-10-29 00:00:00                     -  \n",
       "Duration (days)                            609                     -  \n",
       "Calmar Ratio                           0.14695             -0.001905  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retsx_s1 = retsx.loc[:\"2011\"]\n",
    "retsx_s2 = retsx.loc[\"2012\":]\n",
    "\n",
    "# For each sample + overall calculate performance metrics and display nicely\n",
    "metrics_s1 = calc_performance_metrics(retsx_s1[[\"GMWAX\", \"GMGEX\"]]).T.rename(\n",
    "    columns=lambda x: f\"{x} (Start-2011)\"\n",
    ")\n",
    "\n",
    "metrics_s2 = calc_performance_metrics(retsx_s2[[\"GMWAX\", \"GMGEX\"]]).T.rename(\n",
    "    columns=lambda x: f\"{x} (2012-Present)\"\n",
    ")\n",
    "\n",
    "metrics_overall = calc_performance_metrics(retsx[[\"GMWAX\", \"GMGEX\"]]).T.rename(\n",
    "    columns=lambda x: f\"{x} (Start-Present)\"\n",
    ")\n",
    "\n",
    "# Repeat this exercise to extract the max drawdown on total returns.\n",
    "rets_s1 = rets.loc[:\"2011\"]\n",
    "rets_s2 = rets.loc[\"2012\":]\n",
    "\n",
    "metrics_s1_dd = (\n",
    "    calc_performance_metrics(rets_s1[[\"GMWAX\", \"GMGEX\"]])\n",
    "    .T.rename(columns=lambda x: f\"{x} (Start-2011)\")\n",
    "    .loc[[\"Max Drawdown\", \"Bottom\", \"Peak\", \"Recovery\", \"Duration (days)\"], :]\n",
    ")\n",
    "metrics_s2_dd = (\n",
    "    calc_performance_metrics(rets_s2[[\"GMWAX\", \"GMGEX\"]])\n",
    "    .T.rename(columns=lambda x: f\"{x} (2012-Present)\")\n",
    "    .loc[[\"Max Drawdown\", \"Bottom\", \"Peak\", \"Recovery\", \"Duration (days)\"], :]\n",
    ")\n",
    "metrics_overall_dd = (\n",
    "    calc_performance_metrics(rets[[\"GMWAX\", \"GMGEX\"]])\n",
    "    .T.rename(columns=lambda x: f\"{x} (Start-Present)\")\n",
    "    .loc[[\"Max Drawdown\", \"Bottom\", \"Peak\", \"Recovery\", \"Duration (days)\"], :]\n",
    ")\n",
    "\n",
    "metrics = pd.concat([metrics_s1, metrics_s2, metrics_overall], axis=1)\n",
    "metrics.loc[[\"Max Drawdown\", \"Bottom\", \"Peak\", \"Recovery\", \"Duration (days)\"], :] = (\n",
    "    pd.concat([metrics_s1_dd, metrics_s2_dd, metrics_overall_dd], axis=1)\n",
    ")\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb5a18d",
   "metadata": {},
   "source": [
    "Has the mean/vol/Sharpe changed much since the case?\n",
    "\n",
    "<font color='red'>\n",
    "For GMWAX, not really. The mean went up a bit, the volatility went down a bit, and so the Sharpe ratio went up a bit, but not really by much.\n",
    "</font>\n",
    "\n",
    "(a) Does GMWAX have high or low tail‑risk as seen by these stats?\n",
    "\n",
    "<font color='red'>\n",
    "Seems like pretty low tailrisk, VaR of only 4ish%, max drawdown of ~30% (not super great), and min return of 11-15%.\n",
    "</font>\n",
    "\n",
    "(b) Does that vary much across the two subsamples?\n",
    "\n",
    "<font color='red'>\n",
    "Yes, the tail risk metrics are better in 2012-present than in inception-2011. The max drawdown is only 21% compared to 29%, and the VaR is 4% compared to 4.4%, and also the min return is 11% compared to 15%.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6f3275",
   "metadata": {},
   "source": [
    "3. **Market exposure (GMWAX).** For all three samples, regress **excess returns of GMWAX** on **excess returns of SPY**:\n   - report estimated **alpha**, **beta**, and **R²**\n   - is GMWAX a **low‑beta** strategy? has that changed since the case?\n   - does GMWAX provide **alpha**? has that changed across subsamples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faea6a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY Beta</th>\n",
       "      <th>SPY Alpha</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GMWAX (Start-2011)</th>\n",
       "      <td>0.542128</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.648686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GMGEX (Start-2011)</th>\n",
       "      <td>0.764237</td>\n",
       "      <td>-0.031201</td>\n",
       "      <td>0.725898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GMWAX (2012-Present)</th>\n",
       "      <td>0.581793</td>\n",
       "      <td>-0.033960</td>\n",
       "      <td>0.748747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GMGEX (2012-Present)</th>\n",
       "      <td>0.838118</td>\n",
       "      <td>-0.110164</td>\n",
       "      <td>0.252468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GMWAX (Start-Present)</th>\n",
       "      <td>0.552608</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.680167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GMGEX (Start-Present)</th>\n",
       "      <td>0.786683</td>\n",
       "      <td>-0.064790</td>\n",
       "      <td>0.397891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       SPY Beta  SPY Alpha        R2\n",
       "GMWAX (Start-2011)     0.542128   0.027000  0.648686\n",
       "GMGEX (Start-2011)     0.764237  -0.031201  0.725898\n",
       "GMWAX (2012-Present)   0.581793  -0.033960  0.748747\n",
       "GMGEX (2012-Present)   0.838118  -0.110164  0.252468\n",
       "GMWAX (Start-Present)  0.552608   0.000558  0.680167\n",
       "GMGEX (Start-Present)  0.786683  -0.064790  0.397891"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = {\n",
    "    \"SPY Beta\": [],\n",
    "    \"SPY Alpha\": [],\n",
    "    \"R2\": [],\n",
    "}\n",
    "\n",
    "for sample in [retsx_s1, retsx_s2, retsx]:\n",
    "    X = sm.add_constant(sample[\"SPY\"])\n",
    "    for fund in [\"GMWAX\", \"GMGEX\"]:\n",
    "        y = sample[fund]\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        summary[\"SPY Beta\"].append(model.params[\"SPY\"])\n",
    "        summary[\"SPY Alpha\"].append(model.params[\"const\"] * 12)  # Annualized\n",
    "        summary[\"R2\"].append(model.rsquared)\n",
    "\n",
    "summary_df = pd.DataFrame(\n",
    "    summary,\n",
    "    index=[\n",
    "        \"GMWAX (Start-2011)\",\n",
    "        \"GMGEX (Start-2011)\",\n",
    "        \"GMWAX (2012-Present)\",\n",
    "        \"GMGEX (2012-Present)\",\n",
    "        \"GMWAX (Start-Present)\",\n",
    "        \"GMGEX (Start-Present)\",\n",
    "    ],\n",
    "    columns=[\"SPY Beta\", \"SPY Alpha\", \"R2\"],\n",
    ")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88c9d3d",
   "metadata": {},
   "source": [
    "Is GMWAX a **low‑beta** strategy? has that changed since the case?\n",
    "\n",
    "<font color='red'>\n",
    "I think it depends. Given the context of the case (value investors, long term, etc.) I would say yes they are low beta. Specifically if we think about the context of being primarily long-only equity investors, their beta is between 0.54 and 0.58, which is reasonably low. \n",
    "\n",
    "However, if we compare this to a long-short equity fund, their beta is quite high, i.e. if you're running a hedge fund you should have a beta that is extremely close to 0.\n",
    "\n",
    "Their beta has barely changed since the case and is pretty constant.\n",
    "</font>\n",
    "\n",
    "Does GMWAX provide **alpha**? has that changed across subsamples?\n",
    "\n",
    "<font color='red'>\n",
    "It depends. From inception to 2011, they provided 2.7% annualized alpha, which is good. However, from 2012 to present they actually provide negative 3.4% alpha, which is bad. Overall they provide close to 0 alpha across the full sample (0.0005, or 5 basis points).\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1891e82d",
   "metadata": {},
   "source": [
    "4. **Compare to GMGEX.** Repeat items 1–3 for **GMGEX**. What are key differences between the two strategies?\n\n<font color='red'>\n\n1-3 for GMGEX are above. My conclusion here is that GMGEX just sucks. Specifically, it has negative returns across the full sample, much higher market beta, worse maximum drawdown (76%!). The key difference in the strategies is that GMGEX only aims to beat the MSCI All Country World Index [link](https://www.gmo.com/americas/product-index-page/equities/global-all-country-equity-allocation-strategy/global-equity-allocation-fund---geaf/?accept=Funds), whereas GMWAX is 65% MSCI All Country World Index and 35% Bloomberg US Aggregate Index [link](https://www.gmo.com/americas/product-index-page/multi-asset-class/global-asset-allocation-strategy/global-asset-allocation-fund---gaaf/). \n\n</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "## 3 Forecast Regressions\n\n_This section utilizes data in `gmo_analysis_data.xlsx`._\n\n1. **Lagged regression.** Consider the regression with predictors lagged one period:\n$$\nr^{SPY}_{t} \\;=\\; \\alpha^{SPY,X} \\;+\\; \\big(\\beta^{SPY,X}\\big)^\\prime X_{t-1} \\;+\\; \\epsilon^{SPY,X}_{t}\n\\tag{1}\n$$\n\nEstimate (1) and report the **$R^2$**, as well as the OLS estimates for $\\alpha$ and $\\beta$. Do this for:\n   - $X$ as a single regressor, the **dividend–price** ratio ($DP$)\n   - $X$ as a single regressor, the **earnings–price** ratio ($EP$)\n   - $X$ with **three** regressors: $DP$, $EP$, and the **10‑year yield**  \n   For each, report the **$R^2$**.\n\n<font color='red'>\nNote: For this section, there is some ambiguity as to whether we should use excess or total returns. Here, I will use excess returns because this is most pertinent to forecasting. If I feel confident that I can predict the risk free rate, then we should strip this out and focus on modelling the less-predictable excess returns on their own.\n</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d87fbf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = pd.read_excel(\n",
    "    \"gmo_analysis_data.xlsx\", sheet_name=\"signals\", index_col=\"date\", parse_dates=True\n",
    ").loc[:\"2024-10-31\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22a65c2",
   "metadata": {},
   "source": [
    "#### 3.1 D/P Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fb3b7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>SPY</td>       <th>  R-squared:         </th> <td>   0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 17 Nov 2025</td> <th>  Prob (F-statistic):</th>  <td>0.0304</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>05:04:12</td>     <th>  Log-Likelihood:    </th> <td>  567.58</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   334</td>      <th>  AIC:               </th> <td>  -1131.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   332</td>      <th>  BIC:               </th> <td>  -1124.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>   -0.0171</td> <td>    0.011</td> <td>   -1.519</td> <td> 0.130</td> <td>   -0.039</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SPX D/P</th> <td>    1.3187</td> <td>    0.607</td> <td>    2.174</td> <td> 0.030</td> <td>    0.126</td> <td>    2.512</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>27.416</td> <th>  Durbin-Watson:     </th> <td>   1.957</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  35.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.627</td> <th>  Prob(JB):          </th> <td>2.40e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.975</td> <th>  Cond. No.          </th> <td>    250.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       SPY        & \\textbf{  R-squared:         } &     0.014   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.011   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     4.727   \\\\\n",
       "\\textbf{Date:}             & Mon, 17 Nov 2025 & \\textbf{  Prob (F-statistic):} &   0.0304    \\\\\n",
       "\\textbf{Time:}             &     05:04:12     & \\textbf{  Log-Likelihood:    } &    567.58   \\\\\n",
       "\\textbf{No. Observations:} &         334      & \\textbf{  AIC:               } &    -1131.   \\\\\n",
       "\\textbf{Df Residuals:}     &         332      & \\textbf{  BIC:               } &    -1124.   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                 & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}   &      -0.0171  &        0.011     &    -1.519  &         0.130        &       -0.039    &        0.005     \\\\\n",
       "\\textbf{SPX D/P} &       1.3187  &        0.607     &     2.174  &         0.030        &        0.126    &        2.512     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 27.416 & \\textbf{  Durbin-Watson:     } &    1.957  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   35.086  \\\\\n",
       "\\textbf{Skew:}          & -0.627 & \\textbf{  Prob(JB):          } & 2.40e-08  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.975 & \\textbf{  Cond. No.          } &     250.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    SPY   R-squared:                       0.014\n",
       "Model:                            OLS   Adj. R-squared:                  0.011\n",
       "Method:                 Least Squares   F-statistic:                     4.727\n",
       "Date:                Mon, 17 Nov 2025   Prob (F-statistic):             0.0304\n",
       "Time:                        05:04:12   Log-Likelihood:                 567.58\n",
       "No. Observations:                 334   AIC:                            -1131.\n",
       "Df Residuals:                     332   BIC:                            -1124.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.0171      0.011     -1.519      0.130      -0.039       0.005\n",
       "SPX D/P        1.3187      0.607      2.174      0.030       0.126       2.512\n",
       "==============================================================================\n",
       "Omnibus:                       27.416   Durbin-Watson:                   1.957\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               35.086\n",
       "Skew:                          -0.627   Prob(JB):                     2.40e-08\n",
       "Kurtosis:                       3.975   Cond. No.                         250.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = retsx[\"SPY\"]\n",
    "x = sm.add_constant(signals[\"SPX D/P\"]).shift(1)\n",
    "\n",
    "model_dp = sm.OLS(y, x, missing=\"drop\").fit()\n",
    "\n",
    "model_dp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1501e6f7",
   "metadata": {},
   "source": [
    "#### 3.2 EP Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb806e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>SPY</td>       <th>  R-squared:         </th> <td>   0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 17 Nov 2025</td> <th>  Prob (F-statistic):</th>  <td> 0.121</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>05:04:12</td>     <th>  Log-Likelihood:    </th> <td>  566.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   334</td>      <th>  AIC:               </th> <td>  -1129.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   332</td>      <th>  BIC:               </th> <td>  -1121.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>   -0.0095</td> <td>    0.011</td> <td>   -0.881</td> <td> 0.379</td> <td>   -0.031</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SPX E/P</th> <td>    0.2991</td> <td>    0.192</td> <td>    1.555</td> <td> 0.121</td> <td>   -0.079</td> <td>    0.678</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>24.617</td> <th>  Durbin-Watson:     </th> <td>   1.960</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  30.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.594</td> <th>  Prob(JB):          </th> <td>2.64e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.874</td> <th>  Cond. No.          </th> <td>    79.2</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       SPY        & \\textbf{  R-squared:         } &     0.007   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.004   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     2.418   \\\\\n",
       "\\textbf{Date:}             & Mon, 17 Nov 2025 & \\textbf{  Prob (F-statistic):} &    0.121    \\\\\n",
       "\\textbf{Time:}             &     05:04:12     & \\textbf{  Log-Likelihood:    } &    566.44   \\\\\n",
       "\\textbf{No. Observations:} &         334      & \\textbf{  AIC:               } &    -1129.   \\\\\n",
       "\\textbf{Df Residuals:}     &         332      & \\textbf{  BIC:               } &    -1121.   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                 & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}   &      -0.0095  &        0.011     &    -0.881  &         0.379        &       -0.031    &        0.012     \\\\\n",
       "\\textbf{SPX E/P} &       0.2991  &        0.192     &     1.555  &         0.121        &       -0.079    &        0.678     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 24.617 & \\textbf{  Durbin-Watson:     } &    1.960  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   30.294  \\\\\n",
       "\\textbf{Skew:}          & -0.594 & \\textbf{  Prob(JB):          } & 2.64e-07  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.874 & \\textbf{  Cond. No.          } &     79.2  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    SPY   R-squared:                       0.007\n",
       "Model:                            OLS   Adj. R-squared:                  0.004\n",
       "Method:                 Least Squares   F-statistic:                     2.418\n",
       "Date:                Mon, 17 Nov 2025   Prob (F-statistic):              0.121\n",
       "Time:                        05:04:12   Log-Likelihood:                 566.44\n",
       "No. Observations:                 334   AIC:                            -1129.\n",
       "Df Residuals:                     332   BIC:                            -1121.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.0095      0.011     -0.881      0.379      -0.031       0.012\n",
       "SPX E/P        0.2991      0.192      1.555      0.121      -0.079       0.678\n",
       "==============================================================================\n",
       "Omnibus:                       24.617   Durbin-Watson:                   1.960\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               30.294\n",
       "Skew:                          -0.594   Prob(JB):                     2.64e-07\n",
       "Kurtosis:                       3.874   Cond. No.                         79.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = retsx[\"SPY\"]\n",
    "x = sm.add_constant(signals[\"SPX E/P\"]).shift()\n",
    "\n",
    "model_ep = sm.OLS(y, x, missing=\"drop\").fit()\n",
    "\n",
    "model_ep.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5b5ea9",
   "metadata": {},
   "source": [
    "#### 3.3 All Three Forecast (DP, EP, 10Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa35f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>SPY</td>       <th>  R-squared:         </th> <td>   0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.944</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 17 Nov 2025</td> <th>  Prob (F-statistic):</th>  <td> 0.122</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>05:04:12</td>     <th>  Log-Likelihood:    </th> <td>  568.15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   334</td>      <th>  AIC:               </th> <td>  -1128.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   330</td>      <th>  BIC:               </th> <td>  -1113.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>       <td>   -0.0069</td> <td>    0.016</td> <td>   -0.417</td> <td> 0.677</td> <td>   -0.039</td> <td>    0.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SPX D/P</th>     <td>    0.6594</td> <td>    0.937</td> <td>    0.704</td> <td> 0.482</td> <td>   -1.183</td> <td>    2.502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SPX E/P</th>     <td>    0.1630</td> <td>    0.265</td> <td>    0.616</td> <td> 0.538</td> <td>   -0.358</td> <td>    0.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>T-Note 10YR</th> <td>   -0.2034</td> <td>    0.198</td> <td>   -1.026</td> <td> 0.306</td> <td>   -0.593</td> <td>    0.187</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>26.366</td> <th>  Durbin-Watson:     </th> <td>   1.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  33.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.616</td> <th>  Prob(JB):          </th> <td>6.19e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.932</td> <th>  Cond. No.          </th> <td>    396.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       SPY        & \\textbf{  R-squared:         } &     0.017   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.008   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     1.944   \\\\\n",
       "\\textbf{Date:}             & Mon, 17 Nov 2025 & \\textbf{  Prob (F-statistic):} &    0.122    \\\\\n",
       "\\textbf{Time:}             &     05:04:12     & \\textbf{  Log-Likelihood:    } &    568.15   \\\\\n",
       "\\textbf{No. Observations:} &         334      & \\textbf{  AIC:               } &    -1128.   \\\\\n",
       "\\textbf{Df Residuals:}     &         330      & \\textbf{  BIC:               } &    -1113.   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                     & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}       &      -0.0069  &        0.016     &    -0.417  &         0.677        &       -0.039    &        0.026     \\\\\n",
       "\\textbf{SPX D/P}     &       0.6594  &        0.937     &     0.704  &         0.482        &       -1.183    &        2.502     \\\\\n",
       "\\textbf{SPX E/P}     &       0.1630  &        0.265     &     0.616  &         0.538        &       -0.358    &        0.684     \\\\\n",
       "\\textbf{T-Note 10YR} &      -0.2034  &        0.198     &    -1.026  &         0.306        &       -0.593    &        0.187     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 26.366 & \\textbf{  Durbin-Watson:     } &    1.967  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   33.195  \\\\\n",
       "\\textbf{Skew:}          & -0.616 & \\textbf{  Prob(JB):          } & 6.19e-08  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.932 & \\textbf{  Cond. No.          } &     396.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    SPY   R-squared:                       0.017\n",
       "Model:                            OLS   Adj. R-squared:                  0.008\n",
       "Method:                 Least Squares   F-statistic:                     1.944\n",
       "Date:                Mon, 17 Nov 2025   Prob (F-statistic):              0.122\n",
       "Time:                        05:04:12   Log-Likelihood:                 568.15\n",
       "No. Observations:                 334   AIC:                            -1128.\n",
       "Df Residuals:                     330   BIC:                            -1113.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "const          -0.0069      0.016     -0.417      0.677      -0.039       0.026\n",
       "SPX D/P         0.6594      0.937      0.704      0.482      -1.183       2.502\n",
       "SPX E/P         0.1630      0.265      0.616      0.538      -0.358       0.684\n",
       "T-Note 10YR    -0.2034      0.198     -1.026      0.306      -0.593       0.187\n",
       "==============================================================================\n",
       "Omnibus:                       26.366   Durbin-Watson:                   1.967\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               33.195\n",
       "Skew:                          -0.616   Prob(JB):                     6.19e-08\n",
       "Kurtosis:                       3.932   Cond. No.                         396.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = retsx[\"SPY\"]\n",
    "x = sm.add_constant(signals).shift()\n",
    "\n",
    "model_all = sm.OLS(y, x, missing=\"drop\").fit()\n",
    "\n",
    "model_all.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c1563",
   "metadata": {},
   "source": [
    "2. **Trading strategy from forecasts.** For each of the three regressions:\n   - Build the forecasted SPY return: $\\hat r^{SPY}_{t+1}$ (forecast made using $X_t$ to predict $r^{SPY}_{t+1}$).\n   - Set the scale (portfolio weight) to $w_t = 100 \\,\\hat r^{SPY}_{t+1}$.\n   - Strategy return: $r^x_{t+1} = w_t\\, r^{SPY}_{t+1}$.  \n   For each strategy, compute:\n   - mean, volatility, Sharpe\n   - max drawdown\n   - market **alpha**\n   - market **beta**\n   - market **information ratio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e024a8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All Three</th>\n",
       "      <th>D/P Only</th>\n",
       "      <th>E/P Only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annualized Return</th>\n",
       "      <td>0.097024</td>\n",
       "      <td>0.089093</td>\n",
       "      <td>0.072883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annualized Volatility</th>\n",
       "      <td>0.163234</td>\n",
       "      <td>0.165365</td>\n",
       "      <td>0.133875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annualized Sharpe Ratio</th>\n",
       "      <td>0.594384</td>\n",
       "      <td>0.538765</td>\n",
       "      <td>0.544407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Drawdown</th>\n",
       "      <td>-0.665389</td>\n",
       "      <td>-0.724389</td>\n",
       "      <td>-0.588043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        All Three  D/P Only  E/P Only\n",
       "Annualized Return        0.097024  0.089093  0.072883\n",
       "Annualized Volatility    0.163234  0.165365  0.133875\n",
       "Annualized Sharpe Ratio  0.594384  0.538765  0.544407\n",
       "Max Drawdown            -0.665389 -0.724389 -0.588043"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the return predictions, and align them with the right period\n",
    "all_prediction = model_all.predict(sm.add_constant(signals)).shift()\n",
    "dp_prediction = model_dp.predict(sm.add_constant(signals[\"SPX D/P\"])).shift()\n",
    "ep_prediction = model_ep.predict(sm.add_constant(signals[\"SPX E/P\"])).shift()\n",
    "\n",
    "# Build the strategy weighting in SPY\n",
    "all_weight = 100 * all_prediction\n",
    "dp_weight = 100 * dp_prediction\n",
    "ep_weight = 100 * ep_prediction\n",
    "\n",
    "# Compute the strategy returns\n",
    "all_strat = all_weight * retsx[\"SPY\"]\n",
    "dp_strat = dp_weight * retsx[\"SPY\"]\n",
    "ep_strat = ep_weight * retsx[\"SPY\"]\n",
    "\n",
    "# Univariate risks\n",
    "strat_metrics = calc_performance_metrics(\n",
    "    pd.DataFrame({\"All Three\": all_strat, \"D/P Only\": dp_strat, \"E/P Only\": ep_strat})\n",
    ").T\n",
    "strat_metrics.loc[\n",
    "    [\n",
    "        \"Annualized Return\",\n",
    "        \"Annualized Volatility\",\n",
    "        \"Annualized Sharpe Ratio\",\n",
    "        \"Max Drawdown\",\n",
    "    ],\n",
    "    :,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfb43223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beta</th>\n",
       "      <th>Alpha (Annualized)</th>\n",
       "      <th>Information Ratio (Annualized)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All Three</th>\n",
       "      <td>0.769932</td>\n",
       "      <td>0.034096</td>\n",
       "      <td>0.305119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D/P Only</th>\n",
       "      <td>0.787617</td>\n",
       "      <td>0.024719</td>\n",
       "      <td>0.220838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E/P Only</th>\n",
       "      <td>0.748304</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>0.173812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Beta  Alpha (Annualized)  Information Ratio (Annualized)\n",
       "All Three  0.769932            0.034096                        0.305119\n",
       "D/P Only   0.787617            0.024719                        0.220838\n",
       "E/P Only   0.748304            0.011722                        0.173812"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = {\n",
    "    \"Beta\": [],\n",
    "    \"Alpha (Annualized)\": [],\n",
    "    \"Information Ratio (Annualized)\": [],\n",
    "}\n",
    "\n",
    "for strat in [all_strat, dp_strat, ep_strat]:\n",
    "    X = sm.add_constant(retsx[\"SPY\"])\n",
    "    y = strat\n",
    "    model = sm.OLS(y, X, missing=\"drop\").fit()\n",
    "    summary[\"Beta\"].append(model.params[\"SPY\"])\n",
    "    summary[\"Alpha (Annualized)\"].append(model.params[\"const\"] * 12)\n",
    "    residuals = model.resid\n",
    "    ir = (model.params[\"const\"] * 12) / (residuals.std() * np.sqrt(12))\n",
    "    summary[\"Information Ratio (Annualized)\"].append(ir)\n",
    "\n",
    "summary_df = pd.DataFrame(\n",
    "    summary,\n",
    "    index=[\"All Three\", \"D/P Only\", \"E/P Only\"],\n",
    ")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a2aa8f",
   "metadata": {},
   "source": [
    "3. **Risk characteristics.**\n   - For both strategies, the market, and GMO, compute monthly **VaR** at $\\pi = 0.05$ (use the historical quantile).\n   - The case mentions stocks under‑performed short‑term bonds from 2000–2011. Does the dynamic portfolio above under‑perform the risk‑free rate over this time?\n   - Based on the regression estimates, in how many periods do we estimate a **negative risk premium**?\n   - Do you believe the dynamic strategy takes on **extra risk**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c423611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GMWAX (Start-2011)</th>\n",
       "      <th>GMGEX (Start-2011)</th>\n",
       "      <th>GMWAX (2012-Present)</th>\n",
       "      <th>GMGEX (2012-Present)</th>\n",
       "      <th>GMWAX (Start-Present)</th>\n",
       "      <th>GMGEX (Start-Present)</th>\n",
       "      <th>All Three</th>\n",
       "      <th>D/P Only</th>\n",
       "      <th>E/P Only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annualized Return</th>\n",
       "      <td>0.046422</td>\n",
       "      <td>-0.003823</td>\n",
       "      <td>0.043423</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.045043</td>\n",
       "      <td>-0.001463</td>\n",
       "      <td>0.097024</td>\n",
       "      <td>0.089093</td>\n",
       "      <td>0.072883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VaR (0.05)</th>\n",
       "      <td>-0.044003</td>\n",
       "      <td>-0.082292</td>\n",
       "      <td>-0.040854</td>\n",
       "      <td>-0.068027</td>\n",
       "      <td>-0.041368</td>\n",
       "      <td>-0.076213</td>\n",
       "      <td>-0.051822</td>\n",
       "      <td>-0.049193</td>\n",
       "      <td>-0.048823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  GMWAX (Start-2011) GMGEX (Start-2011) GMWAX (2012-Present)  \\\n",
       "Annualized Return           0.046422          -0.003823             0.043423   \n",
       "VaR (0.05)                 -0.044003          -0.082292            -0.040854   \n",
       "\n",
       "                  GMGEX (2012-Present) GMWAX (Start-Present)  \\\n",
       "Annualized Return             0.001311              0.045043   \n",
       "VaR (0.05)                   -0.068027             -0.041368   \n",
       "\n",
       "                  GMGEX (Start-Present) All Three  D/P Only  E/P Only  \n",
       "Annualized Return             -0.001463  0.097024  0.089093  0.072883  \n",
       "VaR (0.05)                    -0.076213 -0.051822 -0.049193 -0.048823  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([metrics, strat_metrics], axis=1).loc[[\"Annualized Return\", \"VaR (0.05)\"], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5f39a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "All Three    0.060268\n",
       "D/P Only     0.051386\n",
       "E/P Only     0.026740\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dynamic portfolio\n",
    "port = pd.DataFrame(\n",
    "    {\"All Three\": all_strat, \"D/P Only\": dp_strat, \"E/P Only\": ep_strat}\n",
    ").loc[\"2000\":\"2011\"]\n",
    "port.mean() * 12  # Annualized return over 2000-2011"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca7d096",
   "metadata": {},
   "source": [
    "The case mentions stocks under‑performed short‑term bonds from 2000–2011. Does the dynamic portfolio above under‑perform the risk‑free rate over this time?\n\n<font color='red'>\nNo. Note that we computed this all in excess returns, so if the dynamic portfolio had underperformed the risk-free rate, it would have negative excess returns over this period. However, the dynamic portfolio has positive excess returns over this period.\n</font>\n\nBased on the regression estimates, in how many periods do we estimate a **negative risk premium**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2ee73b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All</th>\n",
       "      <th>D/P</th>\n",
       "      <th>E/P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative Risk Premium (%)</th>\n",
       "      <td>0.137725</td>\n",
       "      <td>0.101796</td>\n",
       "      <td>0.002994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative Risk Premium Count</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   All        D/P       E/P\n",
       "Negative Risk Premium (%)     0.137725   0.101796  0.002994\n",
       "Negative Risk Premium Count  46.000000  34.000000  1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative risk premium is when our forecasted return is negative.\n",
    "neg_prediction = pd.DataFrame(\n",
    "    {\n",
    "        \"All\": [\n",
    "            (all_prediction.dropna() < 0).sum() / len(all_prediction.dropna()),\n",
    "            (all_prediction.dropna() < 0).sum(),\n",
    "        ],\n",
    "        \"D/P\": [\n",
    "            (dp_prediction.dropna() < 0).sum() / len(dp_prediction.dropna()),\n",
    "            (dp_prediction.dropna() < 0).sum(),\n",
    "        ],\n",
    "        \"E/P\": [\n",
    "            (ep_prediction.dropna() < 0).sum() / len(ep_prediction.dropna()),\n",
    "            (ep_prediction.dropna() < 0).sum(),\n",
    "        ],\n",
    "    },\n",
    "    index=[\"Negative Risk Premium (%)\", \"Negative Risk Premium Count\"],\n",
    ")\n",
    "neg_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e454c38",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "In all 3 models we rarely have a negative risk premium. This would potentially explain the high market beta we have, as we are almost always long the market.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "source": [
    "## 4 Out‑of‑Sample Forecasting\n\n_This section utilizes data in `gmo_analysis_data.xlsx`._ Focus on using **both** $DP$ and $EP$ as signals in (1). Compute **out‑of‑sample** ($OOS$) statistics:\n\n**Procedure (rolling OOS):**\n- Start at $t=60$.\n- Estimate (1) using data **through** time $t$.\n- Using the estimated parameters and $x_t$, compute the forecast for $t+1$:\n  $$\n  \\hat r^{SPY}_{t+1} \\;=\\; \\hat \\alpha^{SPY,X}_t \\;+\\; \\big(\\hat \\beta^{SPY,X}_t\\big)^\\prime x_t\n  $$\n- Forecast error: $e^{forecast}_{t+1} = r^{SPY}_{t+1} - \\hat r^{SPY}_{t+1}$.\n- Move to $t=61$ and iterate.\n\nAlso compute the **null** forecast and errors:\n$$\n\\bar r^{SPY}_{t+1} = \\frac{1}{t}\\sum_{i=1}^t r^{SPY}_i, \\qquad\ne^{null}_{t+1} = r^{SPY}_{t+1} - \\bar r^{SPY}_{t+1}.\n$$\n\n1. **Report the out‑of‑sample $R^2$**\n$$\nR^2_{OOS} \\;\\equiv\\; 1 - \\frac{\\sum_{i=61}^T \\big(e^{forecast}_i\\big)^2}{\\sum_{i=61}^T \\big(e^{null}_i\\big)^2}\n$$\nDid this forecasting strategy produce a positive $R^2_{OOS}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02abc290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.11416969570045854)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.regression.rolling import RollingOLS\n",
    "\n",
    "\n",
    "def oos_forecast(signals, asset, t=60, rolling=False, roll_exp=False, intercept=True):\n",
    "    \"\"\"\n",
    "    Computes an out-of-sample forecast based on expanding regression periods\n",
    "\n",
    "    signals: DataFrame containing the signals (regressors) to be used in each regression\n",
    "    asset: DataFrame containing the values (returns) of the asset being predicted\n",
    "    t: The minimum number of periods\n",
    "    rolling: False if expanding, else enter an integer window\n",
    "    roll_exp: If using rolling, indicate whether to use expanding up to the minimum periods\n",
    "    intercept: Boolean indicating the inclusion of an intercept in the regressions\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(signals)\n",
    "\n",
    "    if intercept:\n",
    "        signals = sm.add_constant(signals)\n",
    "\n",
    "    if t > n:\n",
    "        raise ValueError(\"Min. periods (t) greater than number of data points\")\n",
    "\n",
    "    output = pd.DataFrame(index=signals.index, columns=[\"Actual\", \"Predicted\", \"Null\"])\n",
    "\n",
    "    # If expanding\n",
    "    if not rolling:\n",
    "        for i in range(t, n):\n",
    "            y = asset.iloc[:i]\n",
    "            x = signals.iloc[:i].shift()\n",
    "\n",
    "            if intercept:\n",
    "                null_pred = y.mean()\n",
    "\n",
    "            else:\n",
    "                null_pred = 0\n",
    "\n",
    "            model = sm.OLS(y, x, missing=\"drop\").fit()\n",
    "\n",
    "            pred_x = signals.iloc[[i - 1]]\n",
    "            pred = model.predict(pred_x)[0]\n",
    "\n",
    "            output.iloc[i][\"Actual\"] = asset.iloc[i]\n",
    "            output.iloc[i][\"Predicted\"] = pred\n",
    "            output.iloc[i][\"Null\"] = null_pred\n",
    "\n",
    "    # If rolling\n",
    "    else:\n",
    "        if rolling > n:\n",
    "            raise ValueError(\"Rolling window greater than number of data points\")\n",
    "\n",
    "        y = asset\n",
    "        x = signals.shift()\n",
    "\n",
    "        if intercept:\n",
    "            if roll_exp:\n",
    "                null_pred = y.rolling(window=rolling, min_periods=0).mean().shift()\n",
    "            else:\n",
    "                null_pred = y.rolling(window=rolling).mean().shift()\n",
    "\n",
    "        else:\n",
    "            null_pred = 0\n",
    "\n",
    "        # When expanding == True, there is a minimum number of observations\n",
    "        # Keep ^ in mind\n",
    "        model = RollingOLS(y, x, window=rolling, expanding=roll_exp).fit()\n",
    "\n",
    "        output[\"Actual\"] = asset\n",
    "        output[\"Predicted\"] = (model.params * signals).dropna().sum(axis=1).shift()\n",
    "        output[\"Null\"] = null_pred\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def oos_r_squared(data):\n",
    "    \"\"\"\n",
    "    Computes the out-of-sample r squared\n",
    "    data: DataFrame containing actual, model-predicted, and null-predicted values\n",
    "    \"\"\"\n",
    "\n",
    "    model_error = data[\"Actual\"] - data[\"Predicted\"]\n",
    "    null_error = data[\"Actual\"] - data[\"Null\"]\n",
    "\n",
    "    r2_oos = 1 - (model_error**2).sum() / (null_error**2).sum()\n",
    "\n",
    "    return r2_oos\n",
    "\n",
    "oos_ep_dp = oos_forecast(signals[[\"SPX D/P\", \"SPX E/P\"]], retsx[\"SPY\"], rolling=60)\n",
    "oos_r_squared(oos_ep_dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba9b91d",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "Nope, it produced a negative $r^{2}$ out-of-sample of -0.09, this means that it fits the data worse than a naive forecast of just using the historical average.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4967e78",
   "metadata": {},
   "source": [
    "2. **Redo 3.2 with OOS forecasts.** How does the OOS strategy compare to the in‑sample version of 3.2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60f7bc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All Three</th>\n",
       "      <th>D/P Only</th>\n",
       "      <th>E/P Only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annualized Return</th>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.075904</td>\n",
       "      <td>0.04398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annualized Volatility</th>\n",
       "      <td>0.354236</td>\n",
       "      <td>0.337267</td>\n",
       "      <td>0.206451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annualized Sharpe Ratio</th>\n",
       "      <td>0.075543</td>\n",
       "      <td>0.225057</td>\n",
       "      <td>0.21303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Drawdown</th>\n",
       "      <td>-0.956592</td>\n",
       "      <td>-0.909461</td>\n",
       "      <td>-0.689213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        All Three  D/P Only  E/P Only\n",
       "Annualized Return         0.02676  0.075904   0.04398\n",
       "Annualized Volatility    0.354236  0.337267  0.206451\n",
       "Annualized Sharpe Ratio  0.075543  0.225057   0.21303\n",
       "Max Drawdown            -0.956592 -0.909461 -0.689213"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just using EP\n",
    "oos_ep = oos_forecast(signals[[\"SPX E/P\"]], retsx[\"SPY\"], rolling=60)\n",
    "oos_dp = oos_forecast(signals[[\"SPX D/P\"]], retsx[\"SPY\"], rolling=60)\n",
    "oos_all = oos_forecast(signals, retsx[\"SPY\"], rolling=60)\n",
    "\n",
    "# Build the strategy weighting in SPY\n",
    "all_weight = 100 * oos_all[\"Predicted\"]\n",
    "dp_weight = 100 * oos_dp[\"Predicted\"]\n",
    "ep_weight = 100 * oos_ep[\"Predicted\"]\n",
    "\n",
    "# Compute the strategy returns\n",
    "all_strat = all_weight * retsx[\"SPY\"]\n",
    "dp_strat = dp_weight * retsx[\"SPY\"]\n",
    "ep_strat = ep_weight * retsx[\"SPY\"]\n",
    "\n",
    "# Univariate risks\n",
    "strat_metrics = calc_performance_metrics(\n",
    "    pd.DataFrame({\"All Three\": all_strat, \"D/P Only\": dp_strat, \"E/P Only\": ep_strat})\n",
    ").T\n",
    "strat_metrics.loc[\n",
    "    [\n",
    "        \"Annualized Return\",\n",
    "        \"Annualized Volatility\",\n",
    "        \"Annualized Sharpe Ratio\",\n",
    "        \"Max Drawdown\",\n",
    "    ],\n",
    "    :,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a598dd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beta</th>\n",
       "      <th>Alpha (Annualized)</th>\n",
       "      <th>Information Ratio (Annualized)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All Three</th>\n",
       "      <td>-0.309545</td>\n",
       "      <td>0.052993</td>\n",
       "      <td>0.150888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D/P Only</th>\n",
       "      <td>-0.028496</td>\n",
       "      <td>0.078319</td>\n",
       "      <td>0.232235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E/P Only</th>\n",
       "      <td>0.131885</td>\n",
       "      <td>0.032804</td>\n",
       "      <td>0.159621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Beta  Alpha (Annualized)  Information Ratio (Annualized)\n",
       "All Three -0.309545            0.052993                        0.150888\n",
       "D/P Only  -0.028496            0.078319                        0.232235\n",
       "E/P Only   0.131885            0.032804                        0.159621"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = {\n",
    "    \"Beta\": [],\n",
    "    \"Alpha (Annualized)\": [],\n",
    "    \"Information Ratio (Annualized)\": [],\n",
    "}\n",
    "\n",
    "for strat in [all_strat, dp_strat, ep_strat]:\n",
    "    X = sm.add_constant(retsx[\"SPY\"])\n",
    "    y = strat\n",
    "    model = sm.OLS(y, X, missing=\"drop\").fit()\n",
    "    summary[\"Beta\"].append(model.params[\"SPY\"])\n",
    "    summary[\"Alpha (Annualized)\"].append(model.params[\"const\"] * 12)\n",
    "    residuals = model.resid\n",
    "    ir = (model.params[\"const\"] * 12) / (residuals.std() * np.sqrt(12))\n",
    "    summary[\"Information Ratio (Annualized)\"].append(ir)\n",
    "\n",
    "summary_df = pd.DataFrame(\n",
    "    summary,\n",
    "    index=[\"All Three\", \"D/P Only\", \"E/P Only\"],\n",
    ")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a791b737",
   "metadata": {},
   "source": [
    "3. **Redo 3.3 with OOS forecasts.** Is the point‑in‑time version of the strategy **riskier**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44d55c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All Three</th>\n",
       "      <th>D/P Only</th>\n",
       "      <th>E/P Only</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annualized Return</th>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.075904</td>\n",
       "      <td>0.04398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VaR (0.05)</th>\n",
       "      <td>-0.105682</td>\n",
       "      <td>-0.072005</td>\n",
       "      <td>-0.059274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  All Three  D/P Only  E/P Only\n",
       "Annualized Return   0.02676  0.075904   0.04398\n",
       "VaR (0.05)        -0.105682 -0.072005 -0.059274"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_metrics.loc[[\"Annualized Return\", \"VaR (0.05)\"], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fdd2ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All</th>\n",
       "      <th>D/P</th>\n",
       "      <th>E/P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative Risk Premium (%)</th>\n",
       "      <td>0.312727</td>\n",
       "      <td>0.258182</td>\n",
       "      <td>0.232727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative Risk Premium Count</th>\n",
       "      <td>86.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   All        D/P        E/P\n",
       "Negative Risk Premium (%)     0.312727   0.258182   0.232727\n",
       "Negative Risk Premium Count  86.000000  71.000000  64.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative risk premium is when our forecasted return is negative.\n",
    "negative_risk_prem_oos = pd.DataFrame(\n",
    "    {\n",
    "        \"All\": [\n",
    "            (oos_all[\"Predicted\"].dropna() < 0).sum()\n",
    "            / len(oos_all[\"Predicted\"].dropna()),\n",
    "            (oos_all[\"Predicted\"].dropna() < 0).sum(),\n",
    "        ],\n",
    "        \"D/P\": [\n",
    "            (oos_dp[\"Predicted\"].dropna() < 0).sum()\n",
    "            / len(oos_dp[\"Predicted\"].dropna()),\n",
    "            (oos_dp[\"Predicted\"].dropna() < 0).sum(),\n",
    "        ],\n",
    "        \"E/P\": [\n",
    "            (oos_ep[\"Predicted\"].dropna() < 0).sum()\n",
    "            / len(oos_ep[\"Predicted\"].dropna()),\n",
    "            (oos_ep[\"Predicted\"].dropna() < 0).sum(),\n",
    "        ],\n",
    "    },\n",
    "    index=[\"Negative Risk Premium (%)\", \"Negative Risk Premium Count\"],\n",
    ")\n",
    "negative_risk_prem_oos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067d98b6",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "Yes, it does seem riskier. The VaR is higher, the max drawdown is higher, the mean is lower, and the vol is higher. Intuitively, this makes sense because we have lookahead bias on our in-sample strategy (using data from the future to forecasst in the past), meaning that the best possible model is being used in-sample, whereas out-of-sample we are using a model that was fit on past data only.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "## 5 EXTRA: ML Forecasts\n",
    "\n",
    "1. **CART.** Re‑do Section 3 using **CART** (e.g., `RandomForestRegressor` from `sklearn.ensemble`). If you want to visualize, try `sklearn.tree`.\n",
    "2. **CART, OOS.** Compute out‑of‑sample stats as in Section 4.\n",
    "3. **Neural Network.** Re‑do Section 3 using a **neural network** (e.g., `MLPRegressor` from `sklearn.neural_network`).\n",
    "4. **NN & CART, OOS.** Compute out‑of‑sample stats as in Section 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce758e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}